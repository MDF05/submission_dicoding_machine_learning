{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Penting**\n",
    "- Jangan mengubah atau menambahkan cell text yang sudah disediakan, Anda hanya perlu mengerjakan cell code yang sudah disediakan.\n",
    "- Pastikan seluruh kriteria memiliki output yang sesuai, karena jika tidak ada output dianggap tidak selesai.\n",
    "- Misal, Anda menggunakan df = df.dropna() silakan gunakan df.isnull().sum() sebagai tanda sudah berhasil. Silakan sesuaikan seluruh output dengan perintah yang sudah disediakan.\n",
    "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
    "- Pastikan Anda menggunakan variabel df dari awal sampai akhir dan tidak diperbolehkan mengganti nama variabel tersebut.\n",
    "- Hapus simbol pagar (#) pada kode yang bertipe komentar jika Anda menerapkan kriteria tambahan\n",
    "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan\n",
    "- Pastikan Anda mengerjakan sesuai section yang sudah diberikan tanpa mengubah judul atau header yang disediakan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **INFORMASI DATASET**\n",
    "\n",
    "Dataset ini menyajikan gambaran mendalam mengenai perilaku transaksi dan pola aktivitas keuangan, sehingga sangat ideal untuk eksplorasi **deteksi penipuan (fraud detection)** dan **identifikasi anomali**. Dataset ini mencakup **2.512 sampel data transaksi**, yang mencakup berbagai atribut transaksi, demografi nasabah, dan pola penggunaan.\n",
    "\n",
    "Setiap entri memberikan wawasan komprehensif terhadap perilaku transaksi, memungkinkan analisis untuk **keamanan finansial** dan pengembangan model prediktif.\n",
    "\n",
    "## Fitur Utama\n",
    "\n",
    "- **`TransactionID`**: Pengidentifikasi unik alfanumerik untuk setiap transaksi.  \n",
    "- **`AccountID`**: ID unik untuk setiap akun, dapat memiliki banyak transaksi.  \n",
    "- **`TransactionAmount`**: Nilai transaksi dalam mata uang, mulai dari pengeluaran kecil hingga pembelian besar.  \n",
    "- **`TransactionDate`**: Tanggal dan waktu transaksi terjadi.  \n",
    "- **`TransactionType`**: Tipe transaksi berupa `'Credit'` atau `'Debit'`.  \n",
    "- **`Location`**: Lokasi geografis transaksi (nama kota di Amerika Serikat).  \n",
    "- **`DeviceID`**: ID perangkat yang digunakan dalam transaksi.  \n",
    "- **`IP Address`**: Alamat IPv4 yang digunakan saat transaksi, dapat berubah untuk beberapa akun.  \n",
    "- **`MerchantID`**: ID unik merchant, menunjukkan merchant utama dan anomali transaksi.  \n",
    "- **`AccountBalance`**: Saldo akun setelah transaksi berlangsung.  \n",
    "- **`PreviousTransactionDate`**: Tanggal transaksi terakhir pada akun, berguna untuk menghitung frekuensi transaksi.  \n",
    "- **`Channel`**: Kanal transaksi seperti `Online`, `ATM`, atau `Branch`.  \n",
    "- **`CustomerAge`**: Usia pemilik akun.  \n",
    "- **`CustomerOccupation`**: Profesi pengguna seperti `Dokter`, `Insinyur`, `Mahasiswa`, atau `Pensiunan`.  \n",
    "- **`TransactionDuration`**: Lama waktu transaksi (dalam detik).  \n",
    "- **`LoginAttempts`**: Jumlah upaya login sebelum transaksiâ€”jumlah tinggi bisa mengindikasikan anomali.\n",
    "\n",
    "Tugas kamu adalah membuat model clustering yang selanjutnya akan digunakan untuk membuat model klasifikasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Import Library**\n",
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning. Semua library yang dibutuhkan harus **import** di **cell** ini, jika ada library yang dijalankan di cell lain maka **submission langsung ditolak**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Memuat Dataset**\n",
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook lalu mengecek informasi dataset sebelum nantinya dilakukan pembersihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "url='https://docs.google.com/spreadsheets/d/e/2PACX-1vTbg5WVW6W3c8SPNUGc3A3AL-AG32TPEQGpdzARfNICMsLFI0LQj0jporhsLCeVhkN5AoRsTkn08AYl/pub?gid=2020477971&single=true&output=csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan 5 baris pertama dengan function head.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tinjau jumlah baris kolom dan jenis data dalam dataset dengan info.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan statistik deskriptif dataset dengan menjalankan describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Pembersihan dan Pra Pemrosesan Data**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Pembersihan Dataset** untuk menjadikan dataset mudah diintepretasi dan bisa dilatih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek dataset menggunakan isnull().sum()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek dataset menggunakan duplicated().sum()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan feature scaling menggunakan MinMaxScaler() untuk fitur numerik.\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan drop pada kolom yang memiliki keterangan id dan IP Address\n",
    "columns_to_drop = ['TransactionID', 'AccountID', 'DeviceID', 'IP Address', 'MerchantID']\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan feature encoding menggunakan LabelEncoder() untuk fitur kategorikal.\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last checking gunakan columns.tolist() untuk checking seluruh fitur yang ada.\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Analisis Clustering**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Analisis Clustering** untuk mengelompokkan data berdasarkan karakteristik yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan jumlah cluster optimal menggunakan metode Elbow Method dan Silhouette Analysis\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(df, kmeans.labels_))\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, inertias, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "\n",
    "# Plot Silhouette Score\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, 'rx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan clustering menggunakan algoritma K-Means\n",
    "optimal_k = 3\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(df)\n",
    "\n",
    "# Menambahkan kolom cluster ke dataset\n",
    "df['Cluster'] = cluster_labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan dataset hasil clustering ke file CSV\n",
    "df.to_csv('data_clustering.csv', index=False)\n",
    "print(\"Dataset hasil clustering telah disimpan sebagai 'data_clustering.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Interpretasi Hasil Clustering**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Interpretasi Hasil Clustering** untuk memberikan makna pada setiap cluster yang telah dibuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menganalisis karakteristik setiap cluster berdasarkan fitur-fitur yang ada\n",
    "cluster_summary = df.groupby('Cluster').agg({\n",
    "    'TransactionAmount': ['mean', 'std'],\n",
    "    'CustomerAge': ['mean', 'std'],\n",
    "    'TransactionDuration': ['mean', 'std'],\n",
    "    'LoginAttempts': ['mean', 'std'],\n",
    "    'AccountBalance': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Analisis karakteristik cluster:\")\n",
    "print(cluster_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memberikan label yang bermakna pada setiap cluster\n",
    "cluster_labels_mapping = {\n",
    "    0: 'Low_Risk_Regular',\n",
    "    1: 'High_Value_Premium', \n",
    "    2: 'Medium_Risk_Standard'\n",
    "}\n",
    "\n",
    "df['Cluster_Label'] = df['Cluster'].map(cluster_labels_mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan dataset dengan label yang bermakna ke file CSV\n",
    "df.to_csv('data_clustering_inverse.csv', index=False)\n",
    "print(\"Dataset dengan label cluster telah disimpan sebagai 'data_clustering_inverse.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Evaluasi Model Clustering**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Evaluasi Model Clustering** untuk mengukur kualitas hasil clustering yang telah dibuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung Silhouette Score untuk mengukur kualitas clustering\n",
    "silhouette_avg = silhouette_score(df.drop(['Cluster', 'Cluster_Label'], axis=1), df['Cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung Inertia untuk mengukur seberapa baik data dikelompokkan\n",
    "inertia = kmeans.inertia_\n",
    "print(f\"Inertia: {inertia:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Kesimpulan dan Rekomendasi**\n",
    "\n",
    "Pada tahap ini, Anda akan memberikan **Kesimpulan dan Rekomendasi** berdasarkan hasil analisis clustering yang telah dilakukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kesimpulan dan Rekomendasi berdasarkan hasil clustering\n",
    "print(\"KESIMPULAN DAN REKOMENDASI\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. Jumlah cluster optimal: 3 cluster\")\n",
    "print(\"2. Silhouette Score menunjukkan kualitas clustering yang baik\")\n",
    "print(\"3. Setiap cluster memiliki karakteristik yang berbeda:\")\n",
    "print(\"   - Cluster 0: Low Risk Regular (transaksi reguler dengan risiko rendah)\")\n",
    "print(\"   - Cluster 1: High Value Premium (transaksi bernilai tinggi)\")\n",
    "print(\"   - Cluster 2: Medium Risk Standard (transaksi standar dengan risiko menengah)\")\n",
    "print(\"4. Rekomendasi: Gunakan hasil clustering ini untuk model klasifikasi selanjutnya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
